{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 2: Predicting Chronic Kidney Disease in Patients\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus on steps exploring data, building models and evaluating the models we build.\n",
    "\n",
    "There are three links you may find important:\n",
    "- [A set of chronic kidney disease (CKD) data and other biological factors](./chronic_kidney_disease_full.csv).\n",
    "- [The CKD data dictionary](./chronic_kidney_disease_header.txt).\n",
    "- [An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD](./chronic_kidney_disease.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Suppose you're working for Mayo Clinic, widely recognized to be the top hospital in the United States. In your work, you've overheard nurses and doctors discuss test results, then arrive at a conclusion as to whether or not someone has developed a particular disease or condition. For example, you might overhear something like:\n",
    "\n",
    "> **Nurse**: Male 57 year-old patient presents with severe chest pain. FDP _(short for fibrin degradation product)_ was elevated at 13. We did an echo _(echocardiogram)_ and it was inconclusive.\n",
    "\n",
    "> **Doctor**: What was his interarm BP? _(blood pressure)_\n",
    "\n",
    "> **Nurse**: Systolic was 140 on the right; 110 on the left.\n",
    "\n",
    "> **Doctor**: Dammit, it's an aortic dissection! Get to the OR _(operating room)_ now!\n",
    "\n",
    "> _(intense music playing)_\n",
    "\n",
    "In this fictitious but [Shonda Rhimes-esque](https://en.wikipedia.org/wiki/Shonda_Rhimes#Grey's_Anatomy,_Private_Practice,_Scandal_and_other_projects_with_ABC) scenario, you might imagine the doctor going through a series of steps like a [flowchart](https://en.wikipedia.org/wiki/Flowchart), or a series of if-this-then-that steps to diagnose a patient. The first steps made the doctor ask what the interarm blood pressure was. Because interarm blood pressure took on the values it took on, the doctor diagnosed the patient with an aortic dissection.\n",
    "\n",
    "Your goal, as a research biostatistical data scientist at the nation's top hospital, is to develop a medical test that can improve upon our current diagnosis system for [chronic kidney disease (CKD)](https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521).\n",
    "\n",
    "**Real-world problem**: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...   pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_solution_df =  pd.read_csv('chronic_kidney_disease_full.csv')\n",
    "kidney_solution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
       "       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad',\n",
       "       'appet', 'pe', 'ane', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_solution_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Predictor | Description             |\n",
    "|-----------|-------------------------|\n",
    "| age       | age                     |\n",
    "| bp        | blood pressure          |\n",
    "| sg        | specific gravity        |\n",
    "| al        | albumin                 |\n",
    "| su        | sugar                   |\n",
    "| rbc       | red blood cells         |\n",
    "| pc        | pus cell                |\n",
    "| pcc       | pus cell clumps         |\n",
    "| ba        | bacteria                |\n",
    "| bgr       | blood glucose random    |\n",
    "| bu        | blood urea              |\n",
    "| sc        | serum creatinine        |\n",
    "| sod       | sodium                  |\n",
    "| pot       | potassium               |\n",
    "| hemo      | hemoglobin              |\n",
    "| pcv       | packed cell volume      |\n",
    "| wc        | white blood cell count  |\n",
    "| rc        | red blood cell count    |\n",
    "| htn       | hypertension            |\n",
    "| dm        | diabetes mellitus       |\n",
    "| cad       | coronary artery disease |\n",
    "| appet     | appetite                |\n",
    "| pe        | pedal edema             |\n",
    "| ane       | anemia                  |\n",
    "| class     | CKD or not              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the data dictionary. What are a few features or relationships you might be interested in checking out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Relationship between artery disease and CKD\n",
    "\n",
    "2) Sodium content and CKD\n",
    "\n",
    "3) Anemia and CKD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 3. How much of the data is missing from each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_solution_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidney_solution_df.dropn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Suppose that I dropped every row that contained at least one missing value. (In the context of analysis with missing data, we call this a \"complete case analysis,\" because we keep only the complete cases!) How many rows would remain in our dataframe? What are at least two downsides to doing this?\n",
    "\n",
    "> There's a good visual on slide 15 of [this deck](https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf) that shows what a complete case analysis looks like if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataframe consists of 400 rows\n",
      "Rows remaining in our dataframe for complete case analysis is 158\n"
     ]
    }
   ],
   "source": [
    "comp_case = kidney_solution_df.dropna()\n",
    "print(f'The original dataframe consists of {len(kidney_solution_df)} rows')\n",
    "print(f'Rows remaining in our dataframe for complete case analysis is {len(comp_case)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsides:\n",
    "\n",
    "1) Data for running machine learning models would reduce leading to High Bias or High Variance.\n",
    "\n",
    "2) Crucial data for other predictors in the dropped rows would be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Thinking critically about how our data were gathered, it's likely that these records were gathered by doctors and nurses. Brainstorm three potential areas (in addition to the missing data we've already discussed) where this data might be inaccurate or imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Outlier Detection\n",
    "\n",
    "2) Self reported data\n",
    "\n",
    "3) Investigate more on distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 6. Suppose that I want to construct a model where no person who has CKD will ever be told that they do not have CKD. What (very simple, no machine learning needed) model can I create that will never tell a person with CKD that they do not have CKD?\n",
    "\n",
    "> Hint: Don't think about `statsmodels` or `scikit-learn` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positive: Someone told they have CKD, but they do not.\n",
    "\n",
    "\n",
    "False Negative: Someone told they do not have CKD, but they do.\n",
    "\n",
    "\n",
    "\n",
    "Answer: Model: Tell everyone that they might have CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. In problem 6, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimised for False Negatives and avoided it completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Thinking ethically, what is at least one disadvantage to the model you described in problem 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costs of unnecesscary tests & Medication for people with no diseases. Especially hard onpeople who do not have health coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Suppose that I want to construct a model where a person who does not have CKD will ever be told that they do have CKD. What (very simple, no machine learning needed) model can I create that will accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell everyone that they do not have CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. In problem 9, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimised for False Positives and avoided it completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Thinking ethically, what is at least one disadvantage to the model you described in problem 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who do have the disease will be wrongly told that they do not. Which is completely ethically wrong.\n",
    "\n",
    "You are letting people who have the disease suffer on without treatment. Kidney Disorder is not a fun game.\n",
    "\n",
    "I hate both these models and they belong in the trash. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Construct a logistic regression model in `sklearn` predicting class from the other variables. You may scale, select/drop, and engineer features as you wish - build a good model! Make sure, however, that you include at least one categorical/dummy feature and at least one quantitative feature.\n",
    "\n",
    "> Hint: Remember to do a train/test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rbc', 'sod', 'pot', 'wbcc', 'rbcc'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age      float64\n",
       "bp       float64\n",
       "sg       float64\n",
       "al       float64\n",
       "su       float64\n",
       "pc        object\n",
       "pcc       object\n",
       "ba        object\n",
       "bgr      float64\n",
       "bu       float64\n",
       "sc       float64\n",
       "hemo     float64\n",
       "pcv      float64\n",
       "htn       object\n",
       "dm        object\n",
       "cad       object\n",
       "appet     object\n",
       "pe        object\n",
       "ane       object\n",
       "class     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the data\n",
    "miss_columns = kidney_solution_df.isnull().sum()[kidney_solution_df.isnull().sum()>=80].index\n",
    "print(miss_columns)\n",
    "\n",
    "kidney_solution_df.drop(columns = miss_columns, inplace = True)\n",
    "kidney_solution_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>380.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age    bp     sg   al   su       rbc        pc         pcc          ba  \\\n",
       "3   48.0  70.0  1.005  4.0  0.0    normal  abnormal     present  notpresent   \n",
       "9   53.0  90.0  1.020  2.0  0.0  abnormal  abnormal     present  notpresent   \n",
       "11  63.0  70.0  1.010  3.0  0.0  abnormal  abnormal     present  notpresent   \n",
       "14  68.0  80.0  1.010  3.0  2.0    normal  abnormal     present     present   \n",
       "20  61.0  80.0  1.015  2.0  0.0  abnormal  abnormal  notpresent  notpresent   \n",
       "\n",
       "      bgr  ...   pcv     wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "3   117.0  ...  32.0   6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "9    70.0  ...  29.0  12100.0   3.7  yes  yes   no   poor   no  yes   ckd  \n",
       "11  380.0  ...  32.0   4500.0   3.8  yes  yes   no   poor  yes   no   ckd  \n",
       "14  157.0  ...  16.0  11000.0   2.6  yes  yes  yes   poor  yes   no   ckd  \n",
       "20  173.0  ...  24.0   9200.0   3.2  yes  yes  yes   poor  yes  yes   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values\n",
    "comp_case.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of categorical columns in the dataset is 11\n",
      "The number of dummy variables created is 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#Getting a list of categorical Columns\n",
    "cat_cols = []\n",
    "for i in comp_case.columns:\n",
    "    if comp_case[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "print (f'The number of categorical columns in the dataset is {len(cat_cols)}')\n",
    "\n",
    "#Creating dummy variables\n",
    "dummydrop = pd.get_dummies(comp_case[cat_cols], drop_first= True)\n",
    "print (f'The number of dummy variables created is {len(dummydrop.columns)}')\n",
    "\n",
    "\n",
    "#Dropping categorical variables from the original dataframe\n",
    "comp_case.drop(cat_cols, 1, inplace = True)\n",
    "\n",
    "#Creating the final complete data after dummy creation\n",
    "preproc = pd.concat([comp_case, dummydrop], 1)\n",
    "preproc.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc['ckd_present'] = 1 - preproc['class_notckd']\n",
    "preproc.drop('class_notckd',1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    115\n",
       "1     43\n",
       "Name: ckd_present, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc['ckd_present'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9913043478260869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/antonypaulson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = preproc.columns[:-1]\n",
    "X = preproc[features]\n",
    "y = preproc['ckd_present']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "cross_score = cross_val_score(logreg, X_train, y_train, cv =5).mean()\n",
    "print(cross_score)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Evaluate the model.\n",
    "\n",
    "### 13. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo',\n",
       "       'pcv', 'wbcc', 'rbcc', 'rbc_normal', 'pc_normal', 'pcc_present',\n",
       "       'ba_present', 'htn_yes', 'dm_yes', 'cad_yes', 'appet_poor', 'pe_yes',\n",
       "       'ane_yes', 'ckd_present'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045149638760167914"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0.045149638760167914,\n",
       " 'bp': 0.12476618603899974,\n",
       " 'sg': -0.0006089696807673807,\n",
       " 'al': 0.0513746719059421,\n",
       " 'su': 0.006012685743718475,\n",
       " 'bgr': 0.08251846653440337,\n",
       " 'bu': 0.15385545558807634,\n",
       " 'sc': 0.039084141058432394,\n",
       " 'sod': -0.2577309730855277,\n",
       " 'pot': -0.009825338090886154,\n",
       " 'hemo': -0.05863915425984504,\n",
       " 'pcv': -0.2045298099670658,\n",
       " 'wbcc': 0.0013768068513019612,\n",
       " 'rbcc': -0.015104656587322964,\n",
       " 'rbc_normal': -0.010860870043051009,\n",
       " 'pc_normal': -0.007620133169904624,\n",
       " 'pcc_present': 0.005336452534485181,\n",
       " 'ba_present': 0.002593282658850127,\n",
       " 'htn_yes': 0.007000639260230749,\n",
       " 'dm_yes': 0.002140682200483976,\n",
       " 'cad_yes': 0.00017934660024748704,\n",
       " 'appet_poor': 0.004525221589536156,\n",
       " 'pe_yes': 0.006279923063398696,\n",
       " 'ane_yes': 0.005244349364931038}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_dict = {preproc.columns[k]: logreg.coef_[0][k] for k in range(len(preproc.columns)-1)}\n",
    "coef_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient for age is 0.0451. This means that with each unit increase in age the logarithm of odds of CKD increases by 0.0451"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your categorical/dummy features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The coefficient for pcc present is 0.00533. This means that with pcc present vs absent, the logarithm of odds of CKD increases by 0.00533"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Despite being a relatively simple model, logistic regression is very widely used in the real world. Why do you think that's the case? Name at least two advantages to using logistic regression as a modeling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to interpret the effect of coefficients on the predicted variables.\n",
    "It is unlike other classification methods which use Euclidean or other distance measures. It works using the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Does it make sense to generate a confusion matrix on our training data or our test data? Why? Generate it on the proper data.\n",
    "\n",
    "> Hint: Once you've generated your predicted $y$ values and you have your observed $y$ values, then it will be easy to [generate a confusion matrix using sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It makes sense to create a confusion matrix on the test data. This is data on which the model has not been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                  30                   0\n",
       "Actual Positive                   1                   9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = logreg.predict(X)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_test), \n",
    "             columns = ['Predicted Negative', 'Predicted Positive'], \n",
    "             index = ['Actual Negative', 'Actual Positive'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In this hospital case, we want to predict CKD. Do we want to optimize for sensitivity, specificity, or something else? Why? (If you don't think there's one clear answer, that's okay! There rarely is. Be sure to defend your conclusion!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would want to optimize for False negatives, cases where there is CKD but predicted negatives. That is I would optimize for sensitivity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 (BONUS). Write a function that will create an ROC curve for you, then plot the ROC curve.\n",
    "\n",
    "Here's a strategy you might consider:\n",
    "1. In order to even begin, you'll need some fit model. Use your logistic regression model from problem 12.\n",
    "2. We want to look at all values of your \"threshold\" - that is, anything where .predict() gives you above your threshold falls in the \"positive class,\" and anything that is below your threshold falls in the \"negative class.\" Start the threshold at 0.\n",
    "3. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "4. Increment your threshold by some \"step.\" Maybe set your step to be 0.01, or even smaller.\n",
    "5. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "6. Repeat steps 3 and 4 until you get to the threshold of 1.\n",
    "7. Plot the values of sensitivity and 1 - specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = [i[1] for i in logreg.predict_proba(X_test)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-3378d74fd7e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtpr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_probs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mfpr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_probs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-3378d74fd7e5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtpr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_probs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mfpr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_probs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-3378d74fd7e5>\u001b[0m in \u001b[0;36mTPR\u001b[0;34m(df, true_col, pred_prob_col, threshold)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Define function to calculate sensitivity. (True positive rate.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mTPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrue_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_prob_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfalse_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_prob_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_positive\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create threshold values.\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "# Define function to calculate sensitivity. (True positive rate.)\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "\n",
    "# Define function to calculate 1 - specificity. (False positive rate.)\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "    \n",
    "# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\n",
    "tpr_values = [TPR(y_pred_test, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "# Plot ROC curve.\n",
    "plt.plot(fpr_values, # False Positive Rate on X-axis\n",
    "         tpr_values, # True Positive Rate on Y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "# Plot baseline. (Perfect overlap between the two populations.)\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Receiver Operating Characteristic Curve', fontsize=22)\n",
    "plt.ylabel('Sensitivity', fontsize=18)\n",
    "plt.xlabel('1 - Specificity', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Suppose you're speaking with the biostatistics lead at Mayo Clinic, who asks you \"Why are unbalanced classes generally a problem? Are they a problem in this particular CKD analysis?\" How would you respond?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced classes are definitely a problem as the model is trained to predict only a certain class with more accuracy. Yes this is a problem in the ckd analysis. The model is trained to predict the non occurence of ckd than it is to predict occurence of CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Suppose you're speaking with a doctor at Mayo Clinic who, despite being very smart, doesn't know much about data science or statistics. How would you explain why unbalanced classes are generally a problem to this doctor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced classes are definitely a problem as the model is trained to predict only a certain class with more accuracy. Yes this is a problem in the ckd analysis. The model is trained to predict the non occurence of ckd than it is to predict occurence of CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Let's create very unbalanced classes just for the sake of this example! Generate very unbalanced classes by [bootstrapping](http://stattrek.com/statistics/dictionary.aspx?definition=sampling_with_replacement) (a.k.a. random sampling with replacement) the majority class.\n",
    "\n",
    "1. The majority class are those individuals with CKD.\n",
    "2. Generate a random sample of size 200,000 of individuals who have CKD **with replacement**. (Consider setting a random seed for this part!)\n",
    "3. Create a new dataframe with the original data plus this random sample of data.\n",
    "4. Now we should have a dataset with around 200,000 observations, of which only about 0.00075% are non-CKD individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_poor</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>ckd_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>44.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>57.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>56.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>33.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    bp     sg   al   su    bgr    bu   sc    sod  pot  ...  \\\n",
       "337  44.0  70.0  1.025  0.0  0.0   92.0  40.0  0.9  141.0  4.9  ...   \n",
       "320  57.0  60.0  1.020  0.0  0.0  105.0  49.0  1.2  150.0  4.7  ...   \n",
       "91   56.0  70.0  1.015  4.0  1.0  210.0  26.0  1.7  136.0  3.8  ...   \n",
       "341  63.0  70.0  1.025  0.0  0.0  130.0  37.0  0.9  150.0  5.0  ...   \n",
       "284  33.0  80.0  1.025  0.0  0.0  100.0  37.0  1.2  142.0  4.0  ...   \n",
       "\n",
       "     pc_normal  pcc_present  ba_present  htn_yes  dm_yes  cad_yes  appet_poor  \\\n",
       "337          1            0           0        0       0        0           0   \n",
       "320          1            0           0        0       0        0           0   \n",
       "91           1            0           0        0       0        0           0   \n",
       "341          1            0           0        0       0        0           0   \n",
       "284          1            0           0        0       0        0           0   \n",
       "\n",
       "     pe_yes  ane_yes  ckd_present  \n",
       "337       0        0            0  \n",
       "320       0        0            0  \n",
       "91        0        0            1  \n",
       "341       0        0            0  \n",
       "284       0        0            0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "boot = resample(preproc, n_samples =200000, random_state=42)\n",
    "boot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Build a logistic regression model on the unbalanced class data and evaluate its performance using whatever method(s) you see fit. How would you describe the impact of unbalanced classes on logistic regression as a classifier?\n",
    "> Be sure to look at how well it performs on non-CKD data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "At this step, you would generally answer the problem! In this situation, you would likely present your model to doctors or administrators at the hospital and show how your model results in reduced false positives/false negatives. Next steps would be to find a way to roll this model and its conclusions out across the hospital so that the outcomes of patients with CKD (and without CKD!) can be improved!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
